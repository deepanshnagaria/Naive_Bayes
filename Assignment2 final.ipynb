{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''importing packages'''\n",
    "\n",
    "\n",
    "import time\n",
    "import numpy\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "\n",
    "\n",
    "'''TIME'''\n",
    "start_time=time.time()\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "porter = PorterStemmer()\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "'''CHANGE THE PATH TO THE PATH OF THE TRAIN DATA (FORM: LABEL..REVIEW)'''\n",
    "\n",
    "\n",
    "X=pd.read_csv(\"C:/Users/DEEPANSH/Desktop/as2.csv\",names = [\"label\", \"review\"])\n",
    "t=[',','.','/',',','!','?']\n",
    "\n",
    "\n",
    "'''PREPROCESSING REMOVAL OF STOPWORDS AND PUNCTUATIONS + STEMMING'''\n",
    "def clean_str(string):\n",
    "    w = nltk.word_tokenize(string)\n",
    "    w = [p.lower() for p in w if not p in stop_words]\n",
    "    s = [p.translate(t) for p in w]\n",
    "    w = [porter.stem(word) for word in w]\n",
    "    string = \" \".join(w)\n",
    "    return string.strip().lower()\n",
    "\n",
    "\n",
    "'''SUMMARISING DATA AND FORMING VOCAB'''\n",
    "list_of_all_lines=list(X['review'])\n",
    "#list_of_all_lines = [clean_str(str(sent)) for sent in list_of_all_lines]\n",
    "m=len(list_of_all_lines)\n",
    "#Initialising a vocablury in a set\n",
    "vocablury = set()\n",
    "\n",
    "\n",
    "for i in list_of_all_lines:\n",
    "\t#Extracting every word possible in the file\n",
    "\t#lower() converts every word in small so that \n",
    "\t#'This' and 'this' are treated as the same word\n",
    "\ttmp = str(i).lower().split()\n",
    "\tvocablury.update(tmp[0:])\n",
    "#Converting into list so that pickle can write it as list easily\n",
    "Matrix_X=[]\n",
    "Matrix_Y=[]\n",
    "vocablury=list(vocablury)\n",
    "y_labels=[1,2,3,4,5]\n",
    "y_labels=list(y_labels)\n",
    "for i in X['label']:\n",
    "    y_labelled=i\n",
    "    dictionary_for_label_of_a_line=dict.fromkeys(y_labels,0)\n",
    "    dictionary_for_label_of_a_line[y_labelled]=1\n",
    "    row_y=list(dictionary_for_label_of_a_line.values())\n",
    "    Matrix_Y.append(row_y)\n",
    "\n",
    "\n",
    "#Converting the data into appropriate input and keeping \n",
    "#number of count every word has in the article \n",
    "#and then extracting the values of the counter dictionary intov\n",
    "#another list and then putting this list in another list which\n",
    "#will ultimately form a list of list which will be the resultant matrix\n",
    "\n",
    "for inp in list_of_all_lines:\n",
    "\ttmp=str(inp).lower().split()\n",
    "\tx_inputs=tmp[1:]\n",
    "\n",
    "\t# Making a dictionary for every line  in which every  \n",
    "\t# element of dictionary is mapped to 0\n",
    "\tdictionary_for_every_line=dict.fromkeys(vocablury,0)\n",
    "\n",
    "\tfor j in x_inputs:\n",
    "\t\t# Counting the Ocuurance of the word j in the line  \n",
    "\t\tdictionary_for_every_line[j]=dictionary_for_every_line[j]+1\n",
    "\t#Extracting the list of values in the counter dictionary\n",
    "\trow_x=list(dictionary_for_every_line.values())\n",
    "\tMatrix_X.append(row_x)\n",
    "\n",
    "\t#Making a similar dictionary for y_labels in which the label which \n",
    "\t#is tagged will be given a value 1\n",
    "    \n",
    "\n",
    "#Sum of column of the Matrix_Y\n",
    "Matrix_Y=numpy.array(Matrix_Y)\n",
    "y_label_column_sum=numpy.sum(Matrix_Y,axis=0)\n",
    "y_label_column_sum=y_label_column_sum.astype(float)\n",
    "\n",
    "'''MAIN ALGO'''\n",
    "#Calculating Phi(i)\n",
    "Phi_List=numpy.divide(y_label_column_sum,m)\n",
    "\n",
    "#Calculating Theta_Matrix\n",
    "Matrix_X=numpy.array(Matrix_X).astype(float)\n",
    "Theta_Matrix=Matrix_X.transpose().dot(Matrix_Y)\n",
    "\n",
    "\n",
    "'''LAPLACE SMOOTHING C=1'''\n",
    "#Adding c=1 to every element \n",
    "# Laplace Smoothing \n",
    "Theta_Matrix=numpy.add(Theta_Matrix,1)\n",
    "\n",
    "#Sum of elements in every column of X_transpose_Y\n",
    "X_transpose_Y_column_sum=numpy.sum(Theta_Matrix,axis=0)\n",
    "\n",
    "Theta_Matrix=numpy.divide(Theta_Matrix,X_transpose_Y_column_sum)\n",
    "#.npy format is platform independent and in binary format \n",
    "#not understandable by us and more efficient\n",
    "\n",
    "numpy.save('Theta_Matrix.npy',Theta_Matrix)\n",
    "\n",
    "numpy.save('Phi_List.npy',Phi_List)\n",
    "\n",
    "\n",
    "'''TEMPORARY FILE FOR VOCAB AND LABELS'''\n",
    "#Vocablury file save in a temporary file\n",
    "with open('vocablury.txt','wb') as file_handler:\n",
    "\tpickle.dump(vocablury,file_handler)\n",
    "#y_labels file save in a temporary file\n",
    "with open('y_labels.txt','wb') as file_handler:\n",
    "\tpickle.dump(y_labels,file_handler)\n",
    "\n",
    "'''DISPLAYING TOTAL TIME HENCE SHOWING COMPLETION'''\n",
    "end_time=time.time()\n",
    "print(\"Time Elapsed = \" + str(end_time-start_time))\n",
    "\n",
    "\n",
    "# We have to save the vocablury set in a file because we are not allowed to\n",
    "# update the vocablury according to the test data and any new word if \n",
    "# came then we ignore that word as if never existed\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''IMPORTING PACKAGES'''\n",
    "import time\n",
    "import numpy\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "start_time=time.time()\n",
    "#Opening a File providing only the read access\n",
    "stop_words = set(stopwords.words('english'))\n",
    "porter = PorterStemmer()\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "'''CHANGE THE PATH TO THE TRAINING DATA (FORM: LABEL:REVIEW)'''\n",
    "X=pd.read_csv(\"C:/Users/DEEPANSH/Desktop/as2t.csv\",names = [\"label\", \"review\"])\n",
    "\n",
    "\n",
    "\n",
    "'''PREPROCESSING OF DATA REMOVAL OF STOPWORDS AND PUNCTUATIONS + STEMMING'''\n",
    "t=[',','.','/',',','!','?']\n",
    "def clean_str(string):\n",
    "    w = nltk.word_tokenize(string)\n",
    "    w = [p.lower() for p in w]\n",
    "    s = [p.translate(t) for p in w]\n",
    "    w = [word for word in s if word.isalpha()]\n",
    "    w = [p for p in w if not p in stop_words]\n",
    "    w = [porter.stem(word) for word in w]\n",
    "    string = \" \".join(w)\n",
    "    return string.strip().lower()\n",
    "\n",
    "\n",
    "\n",
    "'''SUMMARISING DATA'''\n",
    "list_of_all_lines=list(X['review'])\n",
    "#list_of_all_lines = [clean_str(str(sent)) for sent in list_of_all_lines]\n",
    "m=len(list_of_all_lines)\n",
    "\n",
    "\n",
    "'''LOADING TEMPORARY FILE'''\n",
    "with open('vocablury.txt','rb') as file_handler:\n",
    "\tvocablury=pickle.load(file_handler)\n",
    "\n",
    "    \n",
    "    \n",
    "Phi_List=numpy.load('Phi_List.npy')\n",
    "\n",
    "Theta_Matrix=numpy.load('Theta_Matrix.npy')\n",
    "\n",
    "# Converting the data into appropriate input and keeping \n",
    "# number of count every word has in the article \n",
    "# and then extracting the values of the counter dictionary intov\n",
    "# another list and then putting this list in another list which\n",
    "# will ultimately form a list of list which will be the resultant matrix\n",
    "Matrix_X=[]\n",
    "Matrix_Y=[]\n",
    "for i in list_of_all_lines:\n",
    "\ttmp=i.lower().split()\n",
    "\tx_inputs=tmp[0:]\n",
    "\n",
    "\t# Making a dictionary in which every element is mapped to 0\n",
    "\tdictionary_for_every_line=dict.fromkeys(vocablury,0)\n",
    "\n",
    "\tfor j in x_inputs:\n",
    "\t\tif(j in vocablury):\n",
    "\t\t\tdictionary_for_every_line[j]=dictionary_for_every_line[j]+1\n",
    "\t# Extracting the list of values in the counter dictionary\n",
    "\trow_x=list(dictionary_for_every_line.values())\n",
    "\tMatrix_X.append(row_x)\n",
    "\n",
    "\n",
    "y_labels=[1,2,3,4,5]\n",
    "y_labels=list(y_labels)\n",
    "for i in X['label']:\n",
    "    y_labelled=i\n",
    "    dictionary_for_label_of_a_line=dict.fromkeys(y_labels,0)\n",
    "    dictionary_for_label_of_a_line[y_labelled]=1\n",
    "    row_y=list(dictionary_for_label_of_a_line.values())\n",
    "    Matrix_Y.append(row_y)\n",
    "\n",
    "\n",
    "Matrix_X=numpy.array(Matrix_X)\n",
    "Matrix_Y=numpy.array(Matrix_Y)\n",
    "\n",
    "Matrix_Y_into_Column_Y_can_be_called_as_original=[]\n",
    "# Putting observed y_labels into a column \n",
    "for i in Matrix_Y:\n",
    "\tcount=0\n",
    "\tfor j in i:\n",
    "\t\tcount=count+1\n",
    "\t\tif(j==1):\n",
    "\t\t\tMatrix_Y_into_Column_Y_can_be_called_as_original.append(count)\n",
    "\t\t\tbreak\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "'''STORING ORIGNAL OR EXPECTED OUTPUTS IN A TEMPORARY FILE'''\n",
    "with open('Matrix_Y_into_Column_Y_can_be_called_as_original.txt','wb') as file_handler:\n",
    "\tpickle.dump(Matrix_Y_into_Column_Y_can_be_called_as_original,file_handler)\n",
    "\n",
    "    \n",
    "    \n",
    "'''Hessian Matrix''' \n",
    "H_Matrix = numpy.log(Phi_List)+(Matrix_X.dot(numpy.log(Theta_Matrix)))\n",
    "\n",
    "# The Given Data\n",
    "Y_labels_extracted_from_test_data=[]\n",
    "# Here we have classes 1,2,3,4,5,6,7,8 and so here count variable \n",
    "# will also be the class predicted \n",
    "for i in H_Matrix:\n",
    "\tmax_element=numpy.amax(i)\n",
    "\tcount=0\n",
    "\tfor j in i:\n",
    "\t\tcount=count+1\n",
    "\t\tif(j==max_element):\n",
    "\t\t\tY_labels_extracted_from_test_data.append(count)\n",
    "\t\t\tbreak\n",
    "\n",
    "            \n",
    "            \n",
    "'''STORING PREDICTED CLASS BY THE MODEL TEMPORARILY'''\n",
    "with open('Y_labels_extracted_from_test_data.txt','wb') as file_handler:\n",
    "\tpickle.dump(Y_labels_extracted_from_test_data,file_handler)\n",
    "\n",
    "    \n",
    "'''DISPLAYING TOTAL TIME HENCE SHOWING COMPLETION'''\n",
    "end_time = time.time()\n",
    "print(\"Total Time Elapsed \" +str(end_time-start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''IMPORTING PACKAGES'''\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "\n",
    "'''TIME FOR ACCOUNT'''\n",
    "start_time=time.time()\n",
    "# Observed Data/Classification\n",
    "\n",
    "\n",
    "'''TEMPORARY FILES CALLED TO GET THE PREDICTED AND ACTUAL VALUE'''\n",
    "with open('Matrix_Y_into_Column_Y_can_be_called_as_original.txt','rb') as file_handler:\n",
    "\tMatrix_Y_into_Column_Y_can_be_called_as_original=pickle.load(file_handler)\n",
    "# Predicted Data/Classification\n",
    "with open('Y_labels_extracted_from_test_data.txt','rb') as file_handler:\n",
    "\tY_labels_extracted_from_test_data=pickle.load(file_handler)\n",
    "\n",
    "m1=len(Matrix_Y_into_Column_Y_can_be_called_as_original)\n",
    "m2=len(Y_labels_extracted_from_test_data)\n",
    "# Since m1 and m2 are same we can run loop on any one of them\n",
    "count=0.0\n",
    "\n",
    "'''CLACULATING ACCURACY BY THE CLASSICAL PROBLEMS CORRECT/TOTAL'''\n",
    "for i in range(m1):\n",
    "\tif(Matrix_Y_into_Column_Y_can_be_called_as_original[i]==Y_labels_extracted_from_test_data[i]):\n",
    "\t\tcount=count+1\n",
    "accuracy=count/m1*100\n",
    "print(\"The Accuracy of the above Model is \"+str(accuracy))\n",
    "\n",
    "'''DISPLAYING TOTAL TIME HENCE SHOWING COMPLETION'''\n",
    "end_time=time.time()\n",
    "print(\"Time Elapsed \"+str(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
